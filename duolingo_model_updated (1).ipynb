{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqHIVPyK26jy"
      },
      "outputs": [],
      "source": [
        "import pandas \n",
        "import numpy as np \n",
        "import gc\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "from sklearn.preprocessing import * \n",
        "from keras.models import *\n",
        "from keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32B_oD7_HMx8",
        "outputId": "25c117aa-01a6-49a9-c807-7f87c0a95463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-cc01ac5d46c0>:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dataset = np.asarray(np.load('processed.npy')).astype(np.float)\n"
          ]
        }
      ],
      "source": [
        "  \n",
        "#!gzip -dv /content/processed.npy.gz\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/duolingo/processed.rar /content/\n",
        "%pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"processed.rar\", outdir=\"/content\")\n",
        "'''\n",
        "dataset = np.asarray(np.load('processed.npy')).astype(np.float)  \n",
        "\n",
        "# DA CANCELLARE\n",
        "dataset = dataset[0:int(len(dataset)/8)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luDpEHt1I3HT"
      },
      "outputs": [],
      "source": [
        "# constants\n",
        "MINIMUM_ROWS_PER_SEQUENCE = len(dataset[0])\n",
        "TRAIN_TEST_SPLIT = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kz6H-FYMb_JY"
      },
      "outputs": [],
      "source": [
        " \n",
        "np.random.shuffle(dataset)  \n",
        "\n",
        "output = np.array(dataset[:,dataset.shape[1]-1, 0])\n",
        "output = np.expand_dims(output, axis=1) \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[2,:,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7S09iKaZTSA",
        "outputId": "a565272c-86da-436a-99e1-539648f651d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
            "  -1.00000000e+00 -1.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   2.80000000e+01  2.40000000e+01]\n",
            " [ 8.57142857e-01  3.81392500e+06  2.80000000e+01  2.40000000e+01\n",
            "   1.00000000e+00  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.55999000e+05  2.90000000e+01  2.50000000e+01\n",
            "   2.00000000e+00  2.00000000e+00]\n",
            " [ 1.00000000e+00  2.64347000e+05  3.10000000e+01  2.70000000e+01\n",
            "   1.00000000e+00  1.00000000e+00]\n",
            " [ 1.00000000e+00  4.55000000e+02  3.20000000e+01  2.80000000e+01\n",
            "   1.00000000e+00  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.92000000e+02  3.30000000e+01  2.90000000e+01\n",
            "   1.00000000e+00  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.50000000e+02  3.40000000e+01  3.00000000e+01\n",
            "   1.00000000e+00  1.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the new dataset as:\n",
        "# [previous_output, delta, session_seen]\n",
        "for row in range(dataset.shape[0]):\n",
        "    for seq in range(dataset.shape[1]-1, -1, -1):\n",
        "        if seq == 0:\n",
        "            dataset[row,seq,0] = -1\n",
        "        else:\n",
        "            dataset[row,seq,0] = dataset[row,seq-1,0] \n",
        "            if dataset[row,seq,0] == -1 and dataset[row,seq,1] != -1:\n",
        "                dataset[row,seq,0] = 0\n",
        "             "
      ],
      "metadata": {
        "id": "n4CYqYj1a0VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VN7O1JWa1Jm",
        "outputId": "7cc51df0-be67-4c17-dfbf-b72a60b3a311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HUcqLI7jvs2",
        "outputId": "b9a15b88-7a58-4c76-a549-21e9cc259a95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-f04f55616cf1>:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  normalized = np.array(normalized, dtype=np.float)\n",
            "<ipython-input-12-f04f55616cf1>:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dataset = np.array(np.array_split(normalized, len(normalized)/MINIMUM_ROWS_PER_SEQUENCE), dtype=np.float)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#normalization\n",
        " \n",
        "normalized = []\n",
        "\n",
        "index = 0\n",
        "best = 0\n",
        "for el in dataset:\n",
        "  for seq in el:\n",
        "    normalized.append(seq) \n",
        "    if (seq[1] / (3600*24)) > 60: \n",
        "        best = index\n",
        "    index += 1 \n",
        "normalized = np.array(normalized, dtype=np.float) \n",
        "# NOTA: con ReLU fai in modo di non avere ouput negativi\n",
        "scaler = StandardScaler(with_mean = False)\n",
        "\n",
        "scaler.fit(normalized[:,1:2])\n",
        "normalized[:,1:2] /= 3600*24\n",
        "#normalized[:,1:2] = scaler.transform(normalized[:,1:2]) \n",
        "\n",
        "#scaler.fit(normalized[:,4:5])\n",
        "#normalized[:,4:5] = scaler.transform(normalized[:,4:5]) \n",
        "\n",
        "# fixing wrong normalization\n",
        "for i in range(len(normalized)): \n",
        "    if normalized[i][0] == -1:\n",
        "        for k in range(1, len(normalized[i])):\n",
        "            normalized[i][k] = -1\n",
        " \n",
        "\n",
        "dataset = np.array(np.array_split(normalized, len(normalized)/MINIMUM_ROWS_PER_SEQUENCE), dtype=np.float) \n",
        "\n",
        "# leave only p_recall, delta, session_seen\n",
        "dataset = dataset[:,:,[0,1,4]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBE1lK4T_nfT"
      },
      "outputs": [],
      "source": [
        "# RNN input calc\n",
        "rnn_input_test = dataset[int(len(dataset)*TRAIN_TEST_SPLIT):]\n",
        "rnn_input = dataset[:int(len(dataset)*TRAIN_TEST_SPLIT)] \n",
        "output_test = output[int(len(output)*TRAIN_TEST_SPLIT):]\n",
        "output = output[:int(len(output)*TRAIN_TEST_SPLIT)]\n",
        " \n",
        "\n",
        "# momentaneamente usiamo solo train\n",
        "# quando useremo test, dobbiamo fare finta di averlo solo alla fine\n",
        "# ossia non lo normalizziamo all'inizio ma solo dopo l'allenamento\n",
        "# dropout?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rnn_input[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBXtZvk-iVQF",
        "outputId": "946f8fc6-71f7-4131-b540-77e0698d42b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  6.80000000e+01]\n",
            " [ 9.26470588e-01  1.51989699e+01  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.83564815e-02  2.00000000e+00]\n",
            " [ 1.00000000e+00  1.46990741e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  5.76388889e-03  1.00000000e+00]\n",
            " [ 0.00000000e+00  9.28217593e-01  1.00000000e+00]\n",
            " [ 0.00000000e+00  2.01909722e-01  1.00000000e+00]\n",
            " [ 1.00000000e+00  5.78703704e-03  2.00000000e+00]\n",
            " [ 1.00000000e+00  6.05324074e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.88541667e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  7.75509259e-01  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.21990741e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.60069444e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  5.50925926e-03  2.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "weights_calc = np.array([ 0 if i[-3][0] == -1 else 1 for i in rnn_input])\n",
        "print(weights_calc[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7hrraSdUmqE",
        "outputId": "dca6d500-7765-4aae-c707-07e3e04c9f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = rnn_input"
      ],
      "metadata": {
        "id": "plDce_kTEFTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_input = temp"
      ],
      "metadata": {
        "id": "saYf0CemGSA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(int(len(rnn_input)/20)):\n",
        "    idx = random.randint(0, len(rnn_input)-1)\n",
        "    if random.randint(1,1) == 1:\n",
        "        delta = random.randint(1000, 10000)\n",
        "        output[idx][0] = 0\n",
        "        rnn_input[idx][-1][1] = delta \n"
      ],
      "metadata": {
        "id": "H_j3_qzCERo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvTc_fE_gIB6"
      },
      "outputs": [],
      "source": [
        "# creating a weighted loss \n",
        "m = dict()\n",
        "for i in rnn_input:\n",
        "    if i[-3][0] == -1:\n",
        "        continue\n",
        "    if int(i[-1][1]*2.0) not in m:\n",
        "        m[int(i[-1][1]*2.0) ] = 0\n",
        "    m[int(i[-1][1]*2.0)] += 1\n",
        " \n",
        "\n",
        "total_1 = sum([(1 if i[0] == 1 else 0) for i in output])\n",
        "total_0 = sum([(1 if i[0] == 0 else 0) for i in output])\n",
        "total_others = len(output)-total_1-total_0\n",
        "\n",
        "weights_calc = np.array([ 1000.0/(m[1]) if i[-3][0] == -1 else (i[-1][1]*1000.0/m[int(i[-1][1]*2.0)] if m[int(i[-1][1]*2.0)] > 500 else 1000.0/(m[1]))  for i in rnn_input])\n",
        "# weights_calc = np.array([(1 if i[0] != 1 else 1) for i in output]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IocPgDGqN6Zy",
        "outputId": "d2aedda8-2d46-49e8-c673-988a9375a747"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "814"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "m[7]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkqgNDrg-T2r",
        "outputId": "9417bb24-d9e9-43c2-e269-eddd6537fcd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0. ],\n",
              "       [0. ],\n",
              "       [0.5],\n",
              "       ...,\n",
              "       [0.5],\n",
              "       [0. ],\n",
              "       [0. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04YhG8di-bCV",
        "outputId": "4d6efe5b-6900-4225-b02e-1782a824c3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.00097222],\n",
              "       [-0.04383102],\n",
              "       [-0.00108218],\n",
              "       ...,\n",
              "       [-0.00190394],\n",
              "       [-0.00540509],\n",
              "       [-0.39125579]])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "mC_I3vsplEjR",
        "outputId": "80831f72-37df-41f4-9f3a-28dbb1ccb63e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "120/120 [==============================] - 30s 204ms/step - loss: 0.0538 - auc: 0.7388 - MAE: 0.3640 - val_loss: 0.3593 - val_auc: 0.7817 - val_MAE: 0.3593\n",
            "Epoch 2/50\n",
            "120/120 [==============================] - 20s 168ms/step - loss: 0.0501 - auc: 0.7922 - MAE: 0.3351 - val_loss: 0.3472 - val_auc: 0.8247 - val_MAE: 0.3472\n",
            "Epoch 3/50\n",
            "120/120 [==============================] - 20s 169ms/step - loss: 0.0489 - auc: 0.8116 - MAE: 0.3280 - val_loss: 0.3418 - val_auc: 0.8338 - val_MAE: 0.3418\n",
            "Epoch 4/50\n",
            "120/120 [==============================] - 21s 172ms/step - loss: 0.0479 - auc: 0.8219 - MAE: 0.3224 - val_loss: 0.3377 - val_auc: 0.8467 - val_MAE: 0.3377\n",
            "Epoch 5/50\n",
            "120/120 [==============================] - 20s 167ms/step - loss: 0.0470 - auc: 0.8323 - MAE: 0.3156 - val_loss: 0.3266 - val_auc: 0.8170 - val_MAE: 0.3266\n",
            "Epoch 6/50\n",
            "120/120 [==============================] - 20s 169ms/step - loss: 0.0463 - auc: 0.8332 - MAE: 0.3061 - val_loss: 0.3474 - val_auc: 0.8250 - val_MAE: 0.3474\n",
            "Epoch 7/50\n",
            "120/120 [==============================] - 20s 168ms/step - loss: 0.0459 - auc: 0.8301 - MAE: 0.3025 - val_loss: 0.3280 - val_auc: 0.8250 - val_MAE: 0.3280\n",
            "Epoch 8/50\n",
            "107/120 [=========================>....] - ETA: 2s - loss: 0.0453 - auc: 0.8281 - MAE: 0.2974"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-eb5710b578bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# beta regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#print(rnn_input[:6])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_calc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnn_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# we do have 6 elements, each one with: p_recall, delta, history_seen, history_correct, session_seen, session_correct\n",
        "# we keep 5 of those for the LSTM RNN\n",
        "# we use another network with the 6th element and 5 features (all except p_recall)\n",
        "# we connect the networks and try to predict the last p_recall\n",
        "\n",
        "tf.keras.backend.clear_session() \n",
        "\n",
        "rnn_layer_input = Input(shape=rnn_input[0].shape)\n",
        "rnn_layer_0 = Masking(mask_value=-1.0)(rnn_layer_input)   \n",
        "rnn_layer_1 = GRU(30, dropout=.15)(rnn_layer_0)\n",
        "dense_layer_000 = Dense(30, activation='relu') (rnn_layer_1)   \n",
        "dense_layer_00 = Dropout(0.15) (dense_layer_000)   \n",
        "dense_layer_0 = Dense(1, activation='sigmoid', name=\"cases\") (dense_layer_00)  \n",
        "\n",
        "model = Model([rnn_layer_input], [dense_layer_0])\n",
        "metrics=[\"AUC\", \"MAE\"]\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3), loss=\"mae\", metrics=metrics)\n",
        " \n",
        "# beta regression \n",
        "#print(rnn_input[:6])\n",
        "model.fit([rnn_input], output,sample_weight=weights_calc, epochs=50, batch_size=1000, validation_data=([rnn_input_test], output_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xZkHW2VmoFa",
        "outputId": "c54e6e44-1bd8-4c32-d3f5-4cfbad75e8d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [ 9.84615385e-01  1.89668519e+01  1.00000000e+00]\n",
            " [ 1.00000000e+00  3.18634259e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  5.49768519e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.36805556e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.52546296e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  2.61458333e-02  2.00000000e+00]\n",
            " [ 1.00000000e+00  1.96925926e+00  1.00000000e+00]\n",
            " [ 1.00000000e+00  2.41087963e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  4.59490741e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  3.91203704e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  4.12615741e-02  3.00000000e+00]\n",
            " [ 6.66666667e-01  7.27511574e-01  1.00000000e+00]]\n",
            "[0.66666667]\n"
          ]
        }
      ],
      "source": [
        "print(rnn_input[7])\n",
        "print(output[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9m5GhqyLnU4"
      },
      "outputs": [],
      "source": [
        "model.evaluate([rnn_input_test[:,0,:], rnn_input_test[:,1,:],rnn_input_test[:,2,:],rnn_input_test[:,3,:],rnn_input_test[:,4,:],rnn_input_test[:,5,:], dense_input_test], output_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPMAhWaHrzQJ",
        "outputId": "ee189c1c-c67b-4457-a944-64a16b3a50dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.249386574074074"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn_input_test[3][-1][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIObsBd-N6Z1",
        "outputId": "7cf2ac4d-fb2d-4923-dd23-6b0664ebad80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.016168981481481\n"
          ]
        }
      ],
      "source": [
        "maxx = 0\n",
        "for i in rnn_input:\n",
        "    if i[-1][1] > maxx:\n",
        "        maxx = i[-1][1]\n",
        "print(maxx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C6itlhJGJ7ZS",
        "outputId": "8eb0fea2-4c88-4ea2-84b9-6e4c817e9ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            "  [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            "  [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            "  [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            "  [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            "  [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            "  [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            "  [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            "  [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            "  [ 0.00000000e+00  0.00000000e+00  9.00000000e+00]\n",
            "  [ 1.00000000e+00  5.05026620e+00  1.00000000e+00]\n",
            "  [ 0.00000000e+00  1.66666667e-03  1.00000000e+00]\n",
            "  [ 1.00000000e+00  1.04166667e-03  1.00000000e+00]\n",
            "  [ 1.00000000e+00  7.11805556e-03  1.00000000e+00]\n",
            "  [ 0.00000000e+00  7.52314815e-04  1.00000000e+00]\n",
            "  [ 1.00000000e+00  1.66666667e-03  1.00000000e+00]\n",
            "  [ 1.00000000e+00  8.33333333e-04  1.00000000e+00]\n",
            "  [ 1.00000000e+00  1.29347222e+00  1.00000000e+00]\n",
            "  [ 0.00000000e+00  2.54629630e-03  1.00000000e+00]\n",
            "  [ 1.00000000e+00  3.83101852e-03  3.00000000e+00]\n",
            "  [ 1.00000000e+00  1.27314815e-03  1.00000000e+00]\n",
            "  [ 1.00000000e+00  9.49074074e-04  1.00000000e+00]\n",
            "  [ 1.00000000e+00  7.40740741e-04  1.00000000e+00]\n",
            "  [ 1.00000000e+00  3.06712963e-03  2.00000000e+00]\n",
            "  [ 1.00000000e+00  1.01972222e+00  2.00000000e+00]\n",
            "  [ 1.00000000e+00  9.87361111e-01  1.00000000e+00]\n",
            "  [ 1.00000000e+00  8.10185185e-04  1.00000000e+00]\n",
            "  [ 1.00000000e+00  2.81250000e-03  1.00000000e+00]\n",
            "  [ 1.00000000e+00  2.30324074e-03  1.00000000e+00]\n",
            "  [ 1.00000000e+00  9.16875000e-01  1.00000000e+00]\n",
            "  [ 1.00000000e+00  5.09259259e-04  1.00000000e+00]\n",
            "  [ 0.00000000e+00  9.02777778e-04  1.00000000e+00]\n",
            "  [ 1.00000000e+00  6.59722222e-04  1.00000000e+00]\n",
            "  [ 1.00000000e+00  1.25000000e-02  2.00000000e+00]\n",
            "  [ 5.00000000e-01  2.34953704e-03  1.00000000e+00]\n",
            "  [ 0.00000000e+00  9.23877315e-01  1.00000000e+00]\n",
            "  [ 1.00000000e+00  9.02777778e-04  1.00000000e+00]\n",
            "  [ 1.00000000e+00  1.94444444e-03  1.00000000e+00]\n",
            "  [ 1.00000000e+00  8.44907407e-04  1.00000000e+00]\n",
            "  [ 1.00000000e+00  2.25694444e-03  1.00000000e+00]\n",
            "  [ 1.00000000e+00  3.35648148e-03  1.00000000e+00]\n",
            "  [ 0.00000000e+00  9.13518519e-01  1.00000000e+00]\n",
            "  [ 1.00000000e+00  4.43287037e-03  3.00000000e+00]\n",
            "  [ 1.00000000e+00  1.04282407e-02  1.00000000e+00]\n",
            "  [ 1.00000000e+00  8.15972222e-03  1.00000000e+00]\n",
            "  [ 1.00000000e+00  1.07107639e+00  1.00000000e+00]\n",
            "  [ 1.00000000e+00  1.70138889e-03  1.00000000e+00]\n",
            "  [ 1.00000000e+00  2.63888889e-03  1.00000000e+00]\n",
            "  [ 1.00000000e+00  2.68518519e-03  1.00000000e+00]\n",
            "  [ 0.00000000e+00  8.09027778e-03  2.00000000e+00]\n",
            "  [ 1.00000000e+00  8.44907407e-04  1.00000000e+00]]]\n",
            "4617\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "  ind = np.random.randint(0, len(rnn_input_test))\n",
        "  example_rnn = np.array(np.expand_dims(rnn_input_test[ind], 0))\n",
        "  print(example_rnn) \n",
        "  print(ind)\n",
        " \n",
        "  if True:\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(100):\n",
        "      j = (i)\n",
        "      x.append(j)\n",
        "      \n",
        "      example_rnn[0][-6][0] = 1\n",
        "      example_rnn[0][-6][1] = 0\n",
        "      example_rnn[0][-5][0] = 1\n",
        "      example_rnn[0][-5][1] = 0\n",
        "      example_rnn[0][-4][0] = 1\n",
        "      example_rnn[0][-4][1] = 0.01\n",
        "      example_rnn[0][-3][0] = 1\n",
        "      example_rnn[0][-3][1] = 0\n",
        "      example_rnn[0][-2][0] = 1\n",
        "      example_rnn[0][-2][1] = 0.01\n",
        "      \n",
        "      example_rnn[0][-1][1] = j \n",
        "      #print(example_rnn)\n",
        "      #print(model.predict([example_rnn],verbose = 0))\n",
        "      y.append(model.predict([example_rnn],verbose = 0)[0][0])\n",
        "!pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# make data\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "# plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(x, y, linewidth=2.0)\n",
        " \n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}