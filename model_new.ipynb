{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqHIVPyK26jy"
      },
      "outputs": [],
      "source": [
        "import pandas \n",
        "import numpy as np \n",
        "import gc\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "from sklearn.preprocessing import * \n",
        "from keras.models import *\n",
        "from keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32B_oD7_HMx8",
        "outputId": "52bdbfa7-2f79-4f57-8c45-bf9fb6388ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "Mounted at /content/drive\n",
            "patool: Extracting processed.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/processed.rar\n",
            "patool:     with cwd='/content'\n",
            "patool: ... processed.rar extracted to `/content'.\n",
            "gzip: /content/processed.npy.gz: No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-b70a273dde7f>:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dataset = np.asarray(np.load('processed.npy')).astype(np.float)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%pip install patool\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/duolingo/processed.rar /content/\n",
        "\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"processed.rar\", outdir=\"/content\")\n",
        "!gzip -dv /content/processed.npy.gz\n",
        "\n",
        "dataset = np.asarray(np.load('processed.npy')).astype(np.float)  \n",
        "np.random.shuffle(dataset)  \n",
        "dataset = dataset[0:100000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luDpEHt1I3HT"
      },
      "outputs": [],
      "source": [
        "# constants\n",
        "MINIMUM_ROWS_PER_SEQUENCE = len(dataset[0])\n",
        "MAX_AUGMENTATION_DELTA_0 = 1000\n",
        "\n",
        "TRAIN_TEST_SPLIT = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kz6H-FYMb_JY"
      },
      "outputs": [],
      "source": [
        " \n",
        "output = np.array(dataset[:,dataset.shape[1]-1, 0])\n",
        "output = np.expand_dims(output, axis=1) \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "_HUcqLI7jvs2",
        "outputId": "29c3fb60-45cd-4277-ee64-908f1bffab94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnormalized = []\\n\\nindex = 0\\nbest = 0\\nfor el in dataset:\\n  for seq in el:\\n    normalized.append(seq) \\n    if (seq[1] / (3600*24)) > 60: \\n        best = index\\n    index += 1 \\nnormalized = np.array(normalized, dtype=np.float) \\n# NOTA: con ReLU fai in modo di non avere ouput negativi\\nscaler = StandardScaler(with_mean = False)\\n\\nscaler.fit(normalized[:,1:2])\\nnormalized[:,1:2] /= 3600*24\\n#normalized[:,1:2] = scaler.transform(normalized[:,1:2]) \\n\\n#scaler.fit(normalized[:,4:5])\\n#normalized[:,4:5] = scaler.transform(normalized[:,4:5]) \\n\\n# fixing wrong normalization\\nfor i in range(len(normalized)): \\n    if normalized[i][0] == -1:\\n        for k in range(1, len(normalized[i])):\\n            normalized[i][k] = -1\\n \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# creating the new dataset as:\n",
        "# [previous_output, delta]\n",
        "for row in range(dataset.shape[0]):\n",
        "    for seq in range(MINIMUM_ROWS_PER_SEQUENCE-1, -1, -1):\n",
        "        if seq == 0:\n",
        "            dataset[row,seq,0] = -1\n",
        "        else:\n",
        "            dataset[row,seq,0] = dataset[row,seq-1,0] \n",
        "            if dataset[row,seq,0] == -1 and dataset[row,seq,1] != -1:\n",
        "                dataset[row,seq,0] = 0\n",
        "             \n",
        "\n",
        "#normalization\n",
        " \n",
        "# PERCHè non LAYER NORMALIZATION?\n",
        "    \n",
        "'''\n",
        "normalized = []\n",
        "\n",
        "index = 0\n",
        "best = 0\n",
        "for el in dataset:\n",
        "  for seq in el:\n",
        "    normalized.append(seq) \n",
        "    if (seq[1] / (3600*24)) > 60: \n",
        "        best = index\n",
        "    index += 1 \n",
        "normalized = np.array(normalized, dtype=np.float) \n",
        "# NOTA: con ReLU fai in modo di non avere ouput negativi\n",
        "scaler = StandardScaler(with_mean = False)\n",
        "\n",
        "scaler.fit(normalized[:,1:2])\n",
        "normalized[:,1:2] /= 3600*24\n",
        "#normalized[:,1:2] = scaler.transform(normalized[:,1:2]) \n",
        "\n",
        "#scaler.fit(normalized[:,4:5])\n",
        "#normalized[:,4:5] = scaler.transform(normalized[:,4:5]) \n",
        "\n",
        "# fixing wrong normalization\n",
        "for i in range(len(normalized)): \n",
        "    if normalized[i][0] == -1:\n",
        "        for k in range(1, len(normalized[i])):\n",
        "            normalized[i][k] = -1\n",
        " \n",
        "'''\n",
        "#dataset = np.array(np.array_split(normalized, len(normalized)/MINIMUM_ROWS_PER_SEQUENCE), dtype=np.float) \n",
        "\n",
        "#dataset = np.array()\n",
        "# leave only p_recall, delta, session_seen\n",
        "#dataset = dataset[:,:,[0,1,4]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc5rh5cpx4Jo",
        "outputId": "b69da450-b169-4df6-dbee-900951c97da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1],\n",
              "       [2, 1],\n",
              "       [1, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBE1lK4T_nfT"
      },
      "outputs": [],
      "source": [
        "# RNN input calc\n",
        "rnn_input_test = dataset[int(len(dataset)*TRAIN_TEST_SPLIT):]\n",
        "rnn_input = dataset[:int(len(dataset)*TRAIN_TEST_SPLIT)] \n",
        "output_test = output[int(len(output)*TRAIN_TEST_SPLIT):]\n",
        "output = output[:int(len(output)*TRAIN_TEST_SPLIT)]\n",
        " \n",
        "\n",
        "# momentaneamente usiamo solo train\n",
        "# quando useremo test, dobbiamo fare finta di averlo solo alla fine\n",
        "# ossia non lo normalizziamo all'inizio ma solo dopo l'allenamento\n",
        "# dropout?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixp52s7itU-b",
        "outputId": "7df0e4ca-0d37-4e9f-ab8e-15ad57f0d143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90000\n",
            "623651\n"
          ]
        }
      ],
      "source": [
        "# Here we do some data augmentation\n",
        "# for each sample, we add another sample according to the last output\n",
        "\n",
        "adding_input = []\n",
        "adding_output = []\n",
        "for i in range(int(len(rnn_input))):\n",
        "  \n",
        "    did = []\n",
        "    if output[i] == 0:\n",
        "        for i in range(8):\n",
        "            last = np.array(rnn_input[i])\n",
        "            last[-1][1] = random.randint(last[-1][1]+1, last[-1][1]+1+MAX_AUGMENTATION_DELTA_0)\n",
        "            if last[-1][1] not in did:\n",
        "                adding_output.append([0])\n",
        "                adding_input.append(last)\n",
        "                did.append(last[-1][1])\n",
        "    elif rnn_input[i][-1][1] > 0: \n",
        "        for i in range(8):\n",
        "            last = np.array(rnn_input[i])\n",
        "            last[-1][1] = random.randint(0, last[-1][1]-1)\n",
        "            if last[-1][1] not in did:\n",
        "                adding_output.append([1])\n",
        "                adding_input.append(last)\n",
        "                did.append(last[-1][1])\n",
        "\n",
        "print(len(rnn_input))\n",
        "rnn_input = np.concatenate( (rnn_input,np.array(adding_input)) )\n",
        "output = np.concatenate( (output,np.array(adding_output)) )\n",
        "print(len(rnn_input))\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_input[-3]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbTk7SM6xTqI",
        "outputId": "089c2b89-bf5a-437b-ff67-385e9a13497b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -1.,   1.],\n",
              "       [  1.,   3.],\n",
              "       [  0.,   1.],\n",
              "       [  0.,   1.],\n",
              "       [  1.,   3.],\n",
              "       [  1.,   5.],\n",
              "       [  0.,   1.],\n",
              "       [  1.,   3.],\n",
              "       [  1.,   5.],\n",
              "       [  0.,   1.],\n",
              "       [  1.,   3.],\n",
              "       [  1.,   5.],\n",
              "       [  0.,   1.],\n",
              "       [  1.,   3.],\n",
              "       [  1.,   5.],\n",
              "       [  1.,   7.],\n",
              "       [  1.,  15.],\n",
              "       [  1.,  30.],\n",
              "       [  0.,   1.],\n",
              "       [  1., 224.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvTc_fE_gIB6"
      },
      "outputs": [],
      "source": [
        "# creating a weighted loss\n",
        "\n",
        "'''\n",
        "m = dict()\n",
        "for i in rnn_input:\n",
        "    if int(i[-1][1]) not in m:\n",
        "        m[int(i[-1][1]) ] = 0\n",
        "    m[int(i[-1][1])] += 1\n",
        "'''\n",
        "\n",
        "total_1 = sum([(1 if i[0] == 1 else 0) for i in output])\n",
        "total_0 = sum([(1 if i[0] == 0 else 0) for i in output])\n",
        "total_others = len(output)-total_1-total_0\n",
        "\n",
        "# weights_calc = np.array([ 1.0/m[int(i[-1][1])] if m[int(i[-1][1])] > 1000 else 1.0/(m[1])  for i in rnn_input])\n",
        "weights_calc = np.array([(1 if i[0] != 1 else 1) for i in output]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW02SCo1tU-e",
        "outputId": "7a42d6b6-89f4-4a82-88de-83cdc92751dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output[12]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mC_I3vsplEjR",
        "outputId": "43c216eb-3970-4416-d810-d81183f6a3ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "63/63 [==============================] - 9s 99ms/step - loss: 0.4501 - auc: 0.8765 - MAE: 0.2892 - val_loss: 0.5490 - val_auc: 0.5925 - val_MAE: 0.3095\n",
            "Epoch 2/10000\n",
            "63/63 [==============================] - 8s 121ms/step - loss: 0.1801 - auc: 0.9682 - MAE: 0.1098 - val_loss: 0.5475 - val_auc: 0.6441 - val_MAE: 0.2641\n",
            "Epoch 3/10000\n",
            "63/63 [==============================] - 6s 90ms/step - loss: 0.1349 - auc: 0.9793 - MAE: 0.0724 - val_loss: 0.5417 - val_auc: 0.6460 - val_MAE: 0.2755\n",
            "Epoch 4/10000\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.1228 - auc: 0.9831 - MAE: 0.0631 - val_loss: 0.5710 - val_auc: 0.6491 - val_MAE: 0.2557\n",
            "Epoch 5/10000\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.1138 - auc: 0.9859 - MAE: 0.0591 - val_loss: 0.6046 - val_auc: 0.6496 - val_MAE: 0.2431\n",
            "Epoch 6/10000\n",
            "63/63 [==============================] - 6s 90ms/step - loss: 0.1110 - auc: 0.9866 - MAE: 0.0570 - val_loss: 0.5407 - val_auc: 0.6540 - val_MAE: 0.2701\n",
            "Epoch 7/10000\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.1136 - auc: 0.9862 - MAE: 0.0577 - val_loss: 0.5362 - val_auc: 0.6535 - val_MAE: 0.2764\n",
            "Epoch 8/10000\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.1058 - auc: 0.9882 - MAE: 0.0547 - val_loss: 0.5303 - val_auc: 0.6599 - val_MAE: 0.2738\n",
            "Epoch 9/10000\n",
            "63/63 [==============================] - 7s 108ms/step - loss: 0.1017 - auc: 0.9892 - MAE: 0.0533 - val_loss: 0.5123 - val_auc: 0.6648 - val_MAE: 0.3262\n",
            "Epoch 10/10000\n",
            "63/63 [==============================] - 6s 92ms/step - loss: 0.1031 - auc: 0.9886 - MAE: 0.0535 - val_loss: 0.5393 - val_auc: 0.6558 - val_MAE: 0.2730\n",
            "Epoch 11/10000\n",
            "63/63 [==============================] - 6s 90ms/step - loss: 0.1018 - auc: 0.9890 - MAE: 0.0533 - val_loss: 0.5675 - val_auc: 0.6457 - val_MAE: 0.2612\n",
            "Epoch 12/10000\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.0988 - auc: 0.9896 - MAE: 0.0517 - val_loss: 0.5328 - val_auc: 0.6588 - val_MAE: 0.2732\n",
            "Epoch 13/10000\n",
            "63/63 [==============================] - 6s 92ms/step - loss: 0.0982 - auc: 0.9897 - MAE: 0.0517 - val_loss: 0.5261 - val_auc: 0.6541 - val_MAE: 0.2739\n",
            "Epoch 14/10000\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.1001 - auc: 0.9897 - MAE: 0.0527 - val_loss: 0.5154 - val_auc: 0.6592 - val_MAE: 0.3008\n",
            "Epoch 15/10000\n",
            "63/63 [==============================] - 7s 118ms/step - loss: 0.0972 - auc: 0.9900 - MAE: 0.0513 - val_loss: 0.5472 - val_auc: 0.6605 - val_MAE: 0.2639\n",
            "Epoch 16/10000\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.0970 - auc: 0.9901 - MAE: 0.0513 - val_loss: 0.5122 - val_auc: 0.6654 - val_MAE: 0.2910\n",
            "Epoch 17/10000\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.0963 - auc: 0.9902 - MAE: 0.0516 - val_loss: 0.5511 - val_auc: 0.6331 - val_MAE: 0.2802\n",
            "Epoch 18/10000\n",
            "60/63 [===========================>..] - ETA: 0s - loss: 0.0946 - auc: 0.9906 - MAE: 0.0506"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6aa75e5ffaef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# beta regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#print(rnn_input[:6])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_calc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnn_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# we do have 6 elements, each one with: p_recall, delta, history_seen, history_correct, session_seen, session_correct\n",
        "# we keep 5 of those for the LSTM RNN\n",
        "# we use another network with the 6th element and 5 features (all except p_recall)\n",
        "# we connect the networks and try to predict the last p_recall\n",
        "\n",
        "tf.keras.backend.clear_session() \n",
        "from keras import regularizers\n",
        "\n",
        "rnn_layer_input = Input(shape=rnn_input[0].shape)\n",
        "rnn_layer_0 = Masking(mask_value=-1.0)(rnn_layer_input)\n",
        "rnn_layer_1 = GRU(20,dropout=0.1, recurrent_dropout=0.13, kernel_regularizer=regularizers.L2(0.001), recurrent_regularizer=regularizers.L2(0.001))(rnn_layer_0)\n",
        "dense_layer_00 = Dropout(0.13)(Dense(20, activation='relu',  kernel_regularizer=regularizers.L2(0.001), activity_regularizer=regularizers.L2(0.01)) (rnn_layer_1))\n",
        "dense_layer_down = Dense(2, activation=\"relu\")(dense_layer_00)\n",
        "dense_layer_000 = Dense(20, activation=\"sigmoid\")(dense_layer_down)\n",
        "dense_layer_0 = Dense(1, activation='sigmoid', name=\"cases\") (dense_layer_000)  \n",
        "\n",
        "model = Model([rnn_layer_input], [dense_layer_0])\n",
        "metrics=[\"AUC\", \"MAE\"]\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-2), loss=\"binary_crossentropy\", metrics=metrics)\n",
        "\n",
        "\n",
        "# beta regression \n",
        "#print(rnn_input[:6])\n",
        "model.fit([rnn_input], output,sample_weight=weights_calc, epochs=10000, batch_size=10000, validation_data=([rnn_input_test], output_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xZkHW2VmoFa",
        "outputId": "c54e6e44-1bd8-4c32-d3f5-4cfbad75e8d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [ 9.84615385e-01  1.89668519e+01  1.00000000e+00]\n",
            " [ 1.00000000e+00  3.18634259e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  5.49768519e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.36805556e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.52546296e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  2.61458333e-02  2.00000000e+00]\n",
            " [ 1.00000000e+00  1.96925926e+00  1.00000000e+00]\n",
            " [ 1.00000000e+00  2.41087963e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  4.59490741e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  3.91203704e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  4.12615741e-02  3.00000000e+00]\n",
            " [ 6.66666667e-01  7.27511574e-01  1.00000000e+00]]\n",
            "[0.66666667]\n"
          ]
        }
      ],
      "source": [
        "print(rnn_input[7])\n",
        "print(output[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9m5GhqyLnU4"
      },
      "outputs": [],
      "source": [
        "model.evaluate([rnn_input_test[:,0,:], rnn_input_test[:,1,:],rnn_input_test[:,2,:],rnn_input_test[:,3,:],rnn_input_test[:,4,:],rnn_input_test[:,5,:], dense_input_test], output_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPMAhWaHrzQJ",
        "outputId": "ee189c1c-c67b-4457-a944-64a16b3a50dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.249386574074074"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn_input_test[3][-1][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOYzXFPatU-k",
        "outputId": "37de3c3c-c11f-435f-ef73-72c4ec87c587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.016168981481481\n"
          ]
        }
      ],
      "source": [
        "maxx = 0\n",
        "for i in rnn_input:\n",
        "    if i[-1][1] > maxx:\n",
        "        maxx = i[-1][1]\n",
        "print(maxx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6itlhJGJ7ZS",
        "outputId": "955ef4b3-ea84-44ce-b464-9291f0d69633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [ 0.  0.]\n",
            "  [ 0.  1.]\n",
            "  [ 0.  1.]\n",
            "  [ 1.  2.]\n",
            "  [ 0.  1.]\n",
            "  [ 1.  2.]\n",
            "  [ 1.  5.]\n",
            "  [ 1.  7.]\n",
            "  [ 1. 12.]\n",
            "  [ 0.  1.]\n",
            "  [ 0.  1.]\n",
            "  [ 1.  3.]\n",
            "  [ 1.  5.]\n",
            "  [ 1.  7.]\n",
            "  [ 1. 15.]]]\n",
            "7958\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "  ind = np.random.randint(0, len(rnn_input_test))\n",
        "  example_rnn = np.array(np.expand_dims(rnn_input_test[ind], 0))\n",
        "  print(example_rnn) \n",
        "  print(ind)\n",
        " \n",
        "  if True:\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(100):\n",
        "      j = (i)\n",
        "      x.append(j)\n",
        "      \n",
        "      for i in range(len(example_rnn[0])):\n",
        "          example_rnn[0][i][0] = 1\n",
        "          example_rnn[0][i][1] = 100\n",
        "      \n",
        "      example_rnn[0][-1][1] = j \n",
        "      \n",
        "      #print(example_rnn)\n",
        "      #print(model.predict([example_rnn],verbose = 0))\n",
        "      y.append(model.predict([example_rnn],verbose = 0)[0][0])\n",
        "!pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# make data\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "# plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(x, y, linewidth=2.0)\n",
        " \n",
        "\n",
        "plt.show()\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycfarcNDtU-m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}