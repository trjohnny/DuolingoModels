{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqHIVPyK26jy"
      },
      "outputs": [],
      "source": [
        "import pandas \n",
        "import numpy as np \n",
        "import gc\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "from sklearn.preprocessing import * \n",
        "from keras.models import *\n",
        "from keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32B_oD7_HMx8",
        "outputId": "fea2f5c4-2e0b-4ce4-af61-e8fa71ef2843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 3.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "Mounted at /content/drive\n",
            "patool: Extracting processed.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/processed.rar\n",
            "patool:     with cwd='/content'\n",
            "patool: ... processed.rar extracted to `/content'.\n",
            "gzip: /content/processed.npy.gz: No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-977e3b30efe6>:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dataset = np.asarray(np.load('processed.npy')).astype(np.float)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%pip install patool\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/duolingo/processed.rar /content/\n",
        "\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"processed.rar\", outdir=\"/content\")\n",
        "!gzip -dv /content/processed.npy.gz\n",
        "\n",
        "\n",
        "dataset = np.asarray(np.load('processed.npy')).astype(np.float)  \n",
        "np.random.shuffle(dataset)   \n",
        "\n",
        "dataset = dataset[0:1000000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luDpEHt1I3HT"
      },
      "outputs": [],
      "source": [
        "# constants\n",
        "MINIMUM_ROWS_PER_SEQUENCE = len(dataset[0])\n",
        "MAX_AUGMENTATION_DELTA_0 = 1000\n",
        "TRAIN_TEST_SPLIT = 0.9\n",
        "\n",
        "# curve:\n",
        "# p = 2^(−∆/h)\n",
        "# we use all the data except the last element\n",
        "# we predict in one neuron h, then we take in input delta of the last element\n",
        "# and using the formula in another neuron we calculate p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBE1lK4T_nfT"
      },
      "outputs": [],
      "source": [
        "# RNN input calc\n",
        "\n",
        " \n",
        "output = np.array(dataset[:,dataset.shape[1]-1, 0])\n",
        "output = np.expand_dims(output, axis=1) \n",
        "rnn_input = np.array(dataset[:,0:(MINIMUM_ROWS_PER_SEQUENCE-1), :])\n",
        "delta_input = np.array(dataset[:,dataset.shape[1]-1:dataset.shape[1],1]) \n",
        "\n",
        "rnn_input_test = rnn_input[int(len(rnn_input)*TRAIN_TEST_SPLIT):]\n",
        "rnn_input = rnn_input[:int(len(rnn_input)*TRAIN_TEST_SPLIT)] \n",
        "output_test = output[int(len(output)*TRAIN_TEST_SPLIT):]\n",
        "output = output[:int(len(output)*TRAIN_TEST_SPLIT)]\n",
        "delta_input_test = delta_input[int(len(delta_input)*TRAIN_TEST_SPLIT):]\n",
        "delta_input = delta_input[:int(len(delta_input)*TRAIN_TEST_SPLIT)]\n",
        " \n",
        "\n",
        "# momentaneamente usiamo solo train\n",
        "# quando useremo test, dobbiamo fare finta di averlo solo alla fine\n",
        "# ossia non lo normalizziamo all'inizio ma solo dopo l'allenamento\n",
        "# dropout?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixp52s7itU-b",
        "outputId": "e277af86-6abe-49a8-b296-116f811562fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900000\n",
            "6703881\n"
          ]
        }
      ],
      "source": [
        "# Here we do some data augmentation\n",
        "# for each sample, we add another sample according to the last output\n",
        "\n",
        "adding_input_rnn = []\n",
        "adding_input_delta = []\n",
        "adding_output = []\n",
        "for i in range(int(len(rnn_input))):\n",
        "  \n",
        "    did = []\n",
        "    if output[i] == 0:\n",
        "        for i in range(8):\n",
        "            last_rnn = np.array(rnn_input[i])\n",
        "            last_delta = np.array(delta_input[i])\n",
        "            last_delta[0] = random.randint(last_delta[0]+1, last_delta[0]+1+MAX_AUGMENTATION_DELTA_0)\n",
        "            if last_delta[0] not in did:\n",
        "                adding_output.append([0])\n",
        "                adding_input_rnn.append(last_rnn)\n",
        "                adding_input_delta.append(last_delta)\n",
        "                did.append(last_delta[0])\n",
        "    elif delta_input[i][0] > 0: \n",
        "        for i in range(8): \n",
        "            last_rnn = np.array(rnn_input[i])\n",
        "            last_delta = np.array(delta_input[i])\n",
        "            last_delta[0] = random.randint(0, last_delta[0]-1)\n",
        "            if last_delta[0] not in did:\n",
        "                adding_output.append([1])\n",
        "                adding_input_rnn.append(last_rnn)\n",
        "                adding_input_delta.append(last_delta)\n",
        "                did.append(last_delta[0])\n",
        " \n",
        "\n",
        "print(len(rnn_input))\n",
        "rnn_input = np.concatenate( (rnn_input,np.array(adding_input_rnn)) )\n",
        "delta_input = np.concatenate( (delta_input,np.array(adding_input_delta)) )\n",
        "output = np.concatenate( (output,np.array(adding_output)) )\n",
        "print(len(rnn_input))\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvTc_fE_gIB6"
      },
      "outputs": [],
      "source": [
        "# creating a weighted loss\n",
        "\n",
        "'''\n",
        "m = dict()\n",
        "for i in rnn_input:\n",
        "    if int(i[-1][1]) not in m:\n",
        "        m[int(i[-1][1]) ] = 0\n",
        "    m[int(i[-1][1])] += 1\n",
        "'''\n",
        "\n",
        "total_1 = sum([(1 if i[0] == 1 else 0) for i in output])\n",
        "total_0 = sum([(1 if i[0] == 0 else 0) for i in output])\n",
        "total_others = len(output)-total_1-total_0\n",
        "\n",
        "# weights_calc = np.array([ 1.0/m[int(i[-1][1])] if m[int(i[-1][1])] > 1000 else 1.0/(m[1])  for i in rnn_input])\n",
        "weights_calc = np.array([(1 if i[0] != 1 else 1) for i in output]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mC_I3vsplEjR",
        "outputId": "7a12e1eb-9196-4a65-cb0d-ab8aaa3d41d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "90/90 [==============================] - 9s 54ms/step - loss: 1.8306 - auc: 0.4713 - MAE: 0.4912 - val_loss: 0.9882 - val_auc: 0.4847 - val_MAE: 0.4366\n",
            "Epoch 2/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.9208 - auc: 0.5118 - MAE: 0.4291 - val_loss: 0.8188 - val_auc: 0.5467 - val_MAE: 0.4073\n",
            "Epoch 3/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.8107 - auc: 0.5443 - MAE: 0.4092 - val_loss: 0.7494 - val_auc: 0.5603 - val_MAE: 0.3964\n",
            "Epoch 4/10000\n",
            "90/90 [==============================] - 5s 50ms/step - loss: 0.7570 - auc: 0.5568 - MAE: 0.3983 - val_loss: 0.7103 - val_auc: 0.5674 - val_MAE: 0.3880\n",
            "Epoch 5/10000\n",
            "90/90 [==============================] - 5s 50ms/step - loss: 0.7249 - auc: 0.5639 - MAE: 0.3906 - val_loss: 0.6861 - val_auc: 0.5798 - val_MAE: 0.3762\n",
            "Epoch 6/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.7007 - auc: 0.5706 - MAE: 0.3846 - val_loss: 0.6634 - val_auc: 0.5903 - val_MAE: 0.3797\n",
            "Epoch 7/10000\n",
            "90/90 [==============================] - 4s 47ms/step - loss: 0.6824 - auc: 0.5755 - MAE: 0.3798 - val_loss: 0.6533 - val_auc: 0.5881 - val_MAE: 0.3620\n",
            "Epoch 8/10000\n",
            "90/90 [==============================] - 4s 47ms/step - loss: 0.6682 - auc: 0.5792 - MAE: 0.3756 - val_loss: 0.6361 - val_auc: 0.5986 - val_MAE: 0.3757\n",
            "Epoch 9/10000\n",
            "90/90 [==============================] - 4s 45ms/step - loss: 0.6557 - auc: 0.5838 - MAE: 0.3722 - val_loss: 0.6252 - val_auc: 0.6009 - val_MAE: 0.3714\n",
            "Epoch 10/10000\n",
            "90/90 [==============================] - 5s 56ms/step - loss: 0.6452 - auc: 0.5868 - MAE: 0.3692 - val_loss: 0.6171 - val_auc: 0.6043 - val_MAE: 0.3620\n",
            "Epoch 11/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.6364 - auc: 0.5898 - MAE: 0.3666 - val_loss: 0.6103 - val_auc: 0.6062 - val_MAE: 0.3561\n",
            "Epoch 12/10000\n",
            "90/90 [==============================] - 4s 47ms/step - loss: 0.6290 - auc: 0.5918 - MAE: 0.3641 - val_loss: 0.6026 - val_auc: 0.6086 - val_MAE: 0.3588\n",
            "Epoch 13/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.6219 - auc: 0.5945 - MAE: 0.3621 - val_loss: 0.5996 - val_auc: 0.5982 - val_MAE: 0.3493\n",
            "Epoch 14/10000\n",
            "90/90 [==============================] - 4s 47ms/step - loss: 0.6161 - auc: 0.5958 - MAE: 0.3599 - val_loss: 0.5955 - val_auc: 0.6083 - val_MAE: 0.3466\n",
            "Epoch 15/10000\n",
            "90/90 [==============================] - 4s 47ms/step - loss: 0.6103 - auc: 0.5985 - MAE: 0.3581 - val_loss: 0.5901 - val_auc: 0.6024 - val_MAE: 0.3466\n",
            "Epoch 16/10000\n",
            "90/90 [==============================] - 5s 54ms/step - loss: 0.6052 - auc: 0.6003 - MAE: 0.3565 - val_loss: 0.5825 - val_auc: 0.6189 - val_MAE: 0.3534\n",
            "Epoch 17/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.6008 - auc: 0.6017 - MAE: 0.3551 - val_loss: 0.5790 - val_auc: 0.6105 - val_MAE: 0.3458\n",
            "Epoch 18/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5969 - auc: 0.6035 - MAE: 0.3534 - val_loss: 0.5754 - val_auc: 0.6274 - val_MAE: 0.3530\n",
            "Epoch 19/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5930 - auc: 0.6046 - MAE: 0.3524 - val_loss: 0.5726 - val_auc: 0.6159 - val_MAE: 0.3428\n",
            "Epoch 20/10000\n",
            "90/90 [==============================] - 4s 47ms/step - loss: 0.5893 - auc: 0.6065 - MAE: 0.3510 - val_loss: 0.5689 - val_auc: 0.6212 - val_MAE: 0.3445\n",
            "Epoch 21/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5861 - auc: 0.6076 - MAE: 0.3497 - val_loss: 0.5662 - val_auc: 0.6197 - val_MAE: 0.3472\n",
            "Epoch 22/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5832 - auc: 0.6089 - MAE: 0.3488 - val_loss: 0.5648 - val_auc: 0.6205 - val_MAE: 0.3367\n",
            "Epoch 23/10000\n",
            "90/90 [==============================] - 4s 47ms/step - loss: 0.5805 - auc: 0.6096 - MAE: 0.3475 - val_loss: 0.5612 - val_auc: 0.6268 - val_MAE: 0.3388\n",
            "Epoch 24/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5777 - auc: 0.6113 - MAE: 0.3466 - val_loss: 0.5576 - val_auc: 0.6270 - val_MAE: 0.3413\n",
            "Epoch 25/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5748 - auc: 0.6127 - MAE: 0.3457 - val_loss: 0.5560 - val_auc: 0.6233 - val_MAE: 0.3370\n",
            "Epoch 26/10000\n",
            "90/90 [==============================] - 4s 47ms/step - loss: 0.5728 - auc: 0.6131 - MAE: 0.3445 - val_loss: 0.5553 - val_auc: 0.6250 - val_MAE: 0.3310\n",
            "Epoch 27/10000\n",
            "90/90 [==============================] - 5s 51ms/step - loss: 0.5703 - auc: 0.6143 - MAE: 0.3438 - val_loss: 0.5524 - val_auc: 0.6294 - val_MAE: 0.3340\n",
            "Epoch 28/10000\n",
            "90/90 [==============================] - 4s 50ms/step - loss: 0.5681 - auc: 0.6152 - MAE: 0.3429 - val_loss: 0.5518 - val_auc: 0.6223 - val_MAE: 0.3331\n",
            "Epoch 29/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5663 - auc: 0.6160 - MAE: 0.3423 - val_loss: 0.5473 - val_auc: 0.6318 - val_MAE: 0.3349\n",
            "Epoch 30/10000\n",
            "90/90 [==============================] - 4s 47ms/step - loss: 0.5645 - auc: 0.6168 - MAE: 0.3413 - val_loss: 0.5477 - val_auc: 0.6279 - val_MAE: 0.3309\n",
            "Epoch 31/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5628 - auc: 0.6176 - MAE: 0.3409 - val_loss: 0.5469 - val_auc: 0.6282 - val_MAE: 0.3275\n",
            "Epoch 32/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5605 - auc: 0.6190 - MAE: 0.3399 - val_loss: 0.5425 - val_auc: 0.6352 - val_MAE: 0.3333\n",
            "Epoch 33/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5592 - auc: 0.6199 - MAE: 0.3392 - val_loss: 0.5428 - val_auc: 0.6290 - val_MAE: 0.3309\n",
            "Epoch 34/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5574 - auc: 0.6206 - MAE: 0.3385 - val_loss: 0.5393 - val_auc: 0.6342 - val_MAE: 0.3328\n",
            "Epoch 35/10000\n",
            "90/90 [==============================] - 5s 53ms/step - loss: 0.5557 - auc: 0.6214 - MAE: 0.3379 - val_loss: 0.5416 - val_auc: 0.6307 - val_MAE: 0.3231\n",
            "Epoch 36/10000\n",
            "90/90 [==============================] - 4s 49ms/step - loss: 0.5543 - auc: 0.6222 - MAE: 0.3374 - val_loss: 0.5372 - val_auc: 0.6350 - val_MAE: 0.3290\n",
            "Epoch 37/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5531 - auc: 0.6227 - MAE: 0.3369 - val_loss: 0.5379 - val_auc: 0.6361 - val_MAE: 0.3227\n",
            "Epoch 38/10000\n",
            "90/90 [==============================] - 4s 48ms/step - loss: 0.5516 - auc: 0.6234 - MAE: 0.3361 - val_loss: 0.5401 - val_auc: 0.6298 - val_MAE: 0.3174\n",
            "Epoch 39/10000\n",
            "90/90 [==============================] - 5s 54ms/step - loss: 0.5508 - auc: 0.6233 - MAE: 0.3357 - val_loss: 0.5337 - val_auc: 0.6405 - val_MAE: 0.3268\n",
            "Epoch 40/10000\n",
            "90/90 [==============================] - 4s 45ms/step - loss: 0.5497 - auc: 0.6244 - MAE: 0.3351 - val_loss: 0.5344 - val_auc: 0.6311 - val_MAE: 0.3227\n",
            "Epoch 41/10000\n",
            "90/90 [==============================] - 4s 45ms/step - loss: 0.5480 - auc: 0.6256 - MAE: 0.3343 - val_loss: 0.5347 - val_auc: 0.6405 - val_MAE: 0.3185\n",
            "Epoch 42/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5466 - auc: 0.6262 - MAE: 0.3341 - val_loss: 0.5325 - val_auc: 0.6360 - val_MAE: 0.3209\n",
            "Epoch 43/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5455 - auc: 0.6265 - MAE: 0.3334 - val_loss: 0.5282 - val_auc: 0.6450 - val_MAE: 0.3303\n",
            "Epoch 44/10000\n",
            "90/90 [==============================] - 4s 47ms/step - loss: 0.5442 - auc: 0.6280 - MAE: 0.3330 - val_loss: 0.5298 - val_auc: 0.6373 - val_MAE: 0.3198\n",
            "Epoch 45/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5426 - auc: 0.6292 - MAE: 0.3325 - val_loss: 0.5271 - val_auc: 0.6478 - val_MAE: 0.3267\n",
            "Epoch 46/10000\n",
            "90/90 [==============================] - 4s 46ms/step - loss: 0.5420 - auc: 0.6287 - MAE: 0.3320 - val_loss: 0.5302 - val_auc: 0.6361 - val_MAE: 0.3171\n",
            "Epoch 47/10000\n",
            "78/90 [=========================>....] - ETA: 0s - loss: 0.5413 - auc: 0.6299 - MAE: 0.3318"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ee4a51af681b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# beta regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#print(rnn_input[:6])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_calc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnn_input_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# we do have 6 elements, each one with: p_recall, delta, history_seen, history_correct, session_seen, session_correct\n",
        "# we keep 5 of those for the LSTM RNN\n",
        "# we use another network with the 6th element and 5 features (all except p_recall)\n",
        "# we connect the networks and try to predict the last p_recall\n",
        "\n",
        "tf.keras.backend.clear_session() \n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "class HalfLifeLayer(tf.keras.layers.Layer):\n",
        "    \n",
        "  def __init__(self):\n",
        "    super(HalfLifeLayer, self).__init__()\n",
        "\n",
        "  def build(self, input_shape): \n",
        "    return\n",
        "\n",
        "  def call(self, inputs):\n",
        "      # outputs shape \n",
        "      # curve:\n",
        "      # p = 2^(−∆/h)\n",
        "      #tf.keras.backend.print_tensor(inputs, message='y = ')\n",
        "      return tf.pow(2.0, -tf.divide(inputs[:,0:1], inputs[:,1:2]+1e-6))\n",
        "\n",
        "rnn_layer_input = Input(shape=rnn_input[0].shape)\n",
        "rnn_layer_0 = Masking(mask_value=-1.0)(rnn_layer_input)\n",
        "rnn_layer_1 = GRU(20,dropout=0.1, recurrent_dropout=0.13, kernel_regularizer=regularizers.L2(0.001), recurrent_regularizer=regularizers.L2(0.001))(rnn_layer_0)\n",
        "dense_layer_0 = Dropout(0.13)(Dense(20, activation='relu',  kernel_regularizer=regularizers.L2(0.001), activity_regularizer=regularizers.L2(0.01)) (rnn_layer_1))\n",
        "dense_layer_1 = Dense(1, activation='relu', name=\"cases\") (dense_layer_0) \n",
        "\n",
        "delta_layer_input = Input(shape=delta_input[0].shape)\n",
        "merge = concatenate([delta_layer_input, dense_layer_1]) # in order: delta, half life\n",
        "output_layer = HalfLifeLayer()(merge)\n",
        "\n",
        "#dense_layer_000 = Dropout(0.13)(Dense(20, activation='relu',  kernel_regularizer=regularizers.L2(0.001), activity_regularizer=regularizers.L2(0.01)) (rnn_layer_1))\n",
        "#output_layer = Dense(1, activation='sigmoid', name=\"cases\") (dense_layer_000)  \n",
        "\n",
        "model = Model([rnn_layer_input, delta_layer_input], [output_layer])\n",
        "metrics=[\"AUC\", \"MAE\"]\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-2), loss=\"binary_crossentropy\", metrics=metrics)\n",
        "\n",
        "\n",
        "# beta regression \n",
        "#print(rnn_input[:6])\n",
        "model.fit([rnn_input, delta_input], output,sample_weight=weights_calc, epochs=10000, batch_size=10000, validation_data=([rnn_input_test, delta_input_test], output_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xZkHW2VmoFa",
        "outputId": "c54e6e44-1bd8-4c32-d3f5-4cfbad75e8d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [ 9.84615385e-01  1.89668519e+01  1.00000000e+00]\n",
            " [ 1.00000000e+00  3.18634259e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  5.49768519e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.36805556e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.52546296e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  2.61458333e-02  2.00000000e+00]\n",
            " [ 1.00000000e+00  1.96925926e+00  1.00000000e+00]\n",
            " [ 1.00000000e+00  2.41087963e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  4.59490741e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  3.91203704e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  4.12615741e-02  3.00000000e+00]\n",
            " [ 6.66666667e-01  7.27511574e-01  1.00000000e+00]]\n",
            "[0.66666667]\n"
          ]
        }
      ],
      "source": [
        "print(rnn_input[7])\n",
        "print(output[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9m5GhqyLnU4"
      },
      "outputs": [],
      "source": [
        "model.evaluate([rnn_input_test[:,0,:], rnn_input_test[:,1,:],rnn_input_test[:,2,:],rnn_input_test[:,3,:],rnn_input_test[:,4,:],rnn_input_test[:,5,:], dense_input_test], output_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPMAhWaHrzQJ",
        "outputId": "ee189c1c-c67b-4457-a944-64a16b3a50dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.249386574074074"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn_input_test[3][-1][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOYzXFPatU-k",
        "outputId": "37de3c3c-c11f-435f-ef73-72c4ec87c587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.016168981481481\n"
          ]
        }
      ],
      "source": [
        "maxx = 0\n",
        "for i in rnn_input:\n",
        "    if i[-1][1] > maxx:\n",
        "        maxx = i[-1][1]\n",
        "print(maxx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "id": "C6itlhJGJ7ZS",
        "outputId": "1d438125-c4e7-41ae-916f-b4cfa49d1046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [ 0.  0.]\n",
            "  [ 1.  1.]\n",
            "  [ 1.  3.]\n",
            "  [ 1.  9.]\n",
            "  [ 1. 15.]\n",
            "  [ 1. 24.]]]\n",
            "[[38.]]\n",
            "43659\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "  ind = np.random.randint(0, len(rnn_input_test))\n",
        "  example_rnn = np.array(np.expand_dims(rnn_input_test[ind], 0))\n",
        "  example_dense = np.array(np.expand_dims(delta_input_test[ind], 0))\n",
        "  print(example_rnn) \n",
        "  print(example_dense) \n",
        "  print(ind)\n",
        " \n",
        "  if True:\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(100):\n",
        "      j = (i)\n",
        "      x.append(j)\n",
        "      \n",
        "      '''\n",
        "      for i in range(len(example_rnn[0])):\n",
        "          example_rnn[0][i][0] = 1\n",
        "          example_rnn[0][i][1] = 1000\n",
        "      '''\n",
        "      example_dense[0][0] = j \n",
        "      \n",
        "      #print(example_dense)\n",
        "      #print(model.predict([example_rnn],verbose = 0))\n",
        "      y.append(model.predict([example_rnn, example_dense],verbose = 0)[0][0])\n",
        "!pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# make data\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "# plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(x, y, linewidth=2.0)\n",
        " \n",
        "\n",
        "plt.show()\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycfarcNDtU-m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}