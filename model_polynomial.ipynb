{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqHIVPyK26jy"
      },
      "outputs": [],
      "source": [
        "import pandas \n",
        "import numpy as np \n",
        "import gc\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "from sklearn.preprocessing import * \n",
        "from keras.models import *\n",
        "from keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32B_oD7_HMx8",
        "outputId": "35820c80-743c-4841-943d-127ae19c0563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: patool in /usr/local/lib/python3.8/dist-packages (1.12)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "patool: Extracting processed.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/processed.rar\n",
            "patool:     with cwd='/content'\n",
            "patool: ... processed.rar extracted to `/content'.\n",
            "gzip: /content/processed.npy.gz: No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4942054f30d4>:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dataset = np.asarray(np.load('processed.npy')).astype(np.float)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%pip install patool\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/duolingo/processed.rar /content/\n",
        "\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"processed.rar\", outdir=\"/content\")\n",
        "!gzip -dv /content/processed.npy.gz\n",
        "\n",
        "\n",
        "dataset = np.asarray(np.load('processed.npy')).astype(np.float)  \n",
        "np.random.shuffle(dataset)   \n",
        "\n",
        "dataset = dataset[0:100000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luDpEHt1I3HT"
      },
      "outputs": [],
      "source": [
        "# constants\n",
        "MINIMUM_ROWS_PER_SEQUENCE = len(dataset[0])\n",
        "MAX_AUGMENTATION_DELTA_0 = 1000\n",
        "TRAIN_TEST_SPLIT = 0.9\n",
        "\n",
        "# curve:\n",
        "# p = 2^(−∆/h)\n",
        "# we use all the data except the last element\n",
        "# we predict in one neuron h, then we take in input delta of the last element\n",
        "# and using the formula in another neuron we calculate p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBE1lK4T_nfT"
      },
      "outputs": [],
      "source": [
        "# RNN input calc\n",
        "\n",
        " \n",
        "output = np.array(dataset[:,dataset.shape[1]-1, 0])\n",
        "output = np.expand_dims(output, axis=1) \n",
        "rnn_input = np.array(dataset[:,0:(MINIMUM_ROWS_PER_SEQUENCE-1), :])\n",
        "delta_input = np.array(dataset[:,dataset.shape[1]-1:dataset.shape[1],1]) \n",
        "\n",
        "rnn_input_test = rnn_input[int(len(rnn_input)*TRAIN_TEST_SPLIT):]\n",
        "rnn_input = rnn_input[:int(len(rnn_input)*TRAIN_TEST_SPLIT)] \n",
        "output_test = output[int(len(output)*TRAIN_TEST_SPLIT):]\n",
        "output = output[:int(len(output)*TRAIN_TEST_SPLIT)]\n",
        "delta_input_test = delta_input[int(len(delta_input)*TRAIN_TEST_SPLIT):]\n",
        "delta_input = delta_input[:int(len(delta_input)*TRAIN_TEST_SPLIT)]\n",
        " \n",
        "\n",
        "# momentaneamente usiamo solo train\n",
        "# quando useremo test, dobbiamo fare finta di averlo solo alla fine\n",
        "# ossia non lo normalizziamo all'inizio ma solo dopo l'allenamento\n",
        "# dropout?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixp52s7itU-b",
        "outputId": "c48abf77-0f1a-45ed-b91d-5dc50d258b71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90000\n",
            "497776\n"
          ]
        }
      ],
      "source": [
        "# Here we do some data augmentation\n",
        "# for each sample, we add another sample according to the last output\n",
        "\n",
        "adding_input_rnn = []\n",
        "adding_input_delta = []\n",
        "adding_output = []\n",
        "for i in range(int(len(rnn_input))):\n",
        "  \n",
        "    did = []\n",
        "    if output[i] == 0:\n",
        "        for i in range(8):\n",
        "            last_rnn = np.array(rnn_input[i])\n",
        "            last_delta = np.array(delta_input[i])\n",
        "            last_delta[0] = random.randint(last_delta[0]+1, last_delta[0]+1+MAX_AUGMENTATION_DELTA_0)\n",
        "            if last_delta[0] not in did:\n",
        "                adding_output.append([0])\n",
        "                adding_input_rnn.append(last_rnn)\n",
        "                adding_input_delta.append(last_delta)\n",
        "                did.append(last_delta[0])\n",
        "    elif delta_input[i][0] > 0: \n",
        "        for i in range(8): \n",
        "            last_rnn = np.array(rnn_input[i])\n",
        "            last_delta = np.array(delta_input[i])\n",
        "            last_delta[0] = random.randint(0, last_delta[0]-1)\n",
        "            if last_delta[0] not in did:\n",
        "                adding_output.append([1])\n",
        "                adding_input_rnn.append(last_rnn)\n",
        "                adding_input_delta.append(last_delta)\n",
        "                did.append(last_delta[0])\n",
        " \n",
        "\n",
        "print(len(rnn_input))\n",
        "rnn_input = np.concatenate( (rnn_input,np.array(adding_input_rnn)) )\n",
        "delta_input = np.concatenate( (delta_input,np.array(adding_input_delta)) )\n",
        "output = np.concatenate( (output,np.array(adding_output)) )\n",
        "print(len(rnn_input))\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvTc_fE_gIB6"
      },
      "outputs": [],
      "source": [
        "# creating a weighted loss\n",
        "\n",
        "'''\n",
        "m = dict()\n",
        "for i in rnn_input:\n",
        "    if int(i[-1][1]) not in m:\n",
        "        m[int(i[-1][1]) ] = 0\n",
        "    m[int(i[-1][1])] += 1\n",
        "'''\n",
        "\n",
        "total_1 = sum([(1 if i[0] == 1 else 0) for i in output])\n",
        "total_0 = sum([(1 if i[0] == 0 else 0) for i in output])\n",
        "total_others = len(output)-total_1-total_0\n",
        "\n",
        "# weights_calc = np.array([ 1.0/m[int(i[-1][1])] if m[int(i[-1][1])] > 1000 else 1.0/(m[1])  for i in rnn_input])\n",
        "weights_calc = np.array([(1 if i[0] != 1 else 1) for i in output]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mC_I3vsplEjR",
        "outputId": "142dc072-b8b3-4adf-c721-41b669cf7643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "50/50 [==============================] - 8s 100ms/step - loss: 0.3012 - MAE: 0.2193 - val_loss: 0.5527 - val_MAE: 0.4930\n",
            "Epoch 2/10000\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2058 - MAE: 0.1592 - val_loss: 0.4976 - val_MAE: 0.4508\n",
            "Epoch 3/10000\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.1787 - MAE: 0.1416 - val_loss: 0.4674 - val_MAE: 0.4238\n",
            "Epoch 4/10000\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.1639 - MAE: 0.1314 - val_loss: 0.4474 - val_MAE: 0.4036\n",
            "Epoch 5/10000\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.1542 - MAE: 0.1244 - val_loss: 0.4332 - val_MAE: 0.3926\n",
            "Epoch 6/10000\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.1470 - MAE: 0.1193 - val_loss: 0.4217 - val_MAE: 0.3822\n",
            "Epoch 7/10000\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.1414 - MAE: 0.1151 - val_loss: 0.4114 - val_MAE: 0.3713\n",
            "Epoch 8/10000\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.1368 - MAE: 0.1117 - val_loss: 0.4037 - val_MAE: 0.3661\n",
            "Epoch 9/10000\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1329 - MAE: 0.1089 - val_loss: 0.3973 - val_MAE: 0.3606\n",
            "Epoch 10/10000\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.1295 - MAE: 0.1065 - val_loss: 0.3900 - val_MAE: 0.3518\n",
            "Epoch 11/10000\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.1266 - MAE: 0.1043 - val_loss: 0.3842 - val_MAE: 0.3458\n",
            "Epoch 12/10000\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.1239 - MAE: 0.1024 - val_loss: 0.3800 - val_MAE: 0.3445\n",
            "Epoch 13/10000\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.1216 - MAE: 0.1008 - val_loss: 0.3756 - val_MAE: 0.3399\n",
            "Epoch 14/10000\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.1195 - MAE: 0.0994 - val_loss: 0.3710 - val_MAE: 0.3339\n",
            "Epoch 15/10000\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.1177 - MAE: 0.0980 - val_loss: 0.3673 - val_MAE: 0.3308\n",
            "Epoch 16/10000\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.1159 - MAE: 0.0967 - val_loss: 0.3647 - val_MAE: 0.3311\n",
            "Epoch 17/10000\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.1143 - MAE: 0.0957 - val_loss: 0.3603 - val_MAE: 0.3242\n",
            "Epoch 18/10000\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1128 - MAE: 0.0946 - val_loss: 0.3586 - val_MAE: 0.3262\n",
            "Epoch 19/10000\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.1114 - MAE: 0.0937 - val_loss: 0.3547 - val_MAE: 0.3180\n",
            "Epoch 20/10000\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.1102 - MAE: 0.0928 - val_loss: 0.3532 - val_MAE: 0.3223\n",
            "Epoch 21/10000\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.1090 - MAE: 0.0921 - val_loss: 0.3498 - val_MAE: 0.3165\n",
            "Epoch 22/10000\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.1079 - MAE: 0.0913 - val_loss: 0.3473 - val_MAE: 0.3154\n",
            "Epoch 23/10000\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.1069 - MAE: 0.0906 - val_loss: 0.3456 - val_MAE: 0.3147\n",
            "Epoch 24/10000\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.1059 - MAE: 0.0899 - val_loss: 0.3440 - val_MAE: 0.3142\n",
            "Epoch 25/10000\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.1050 - MAE: 0.0895 - val_loss: 0.3416 - val_MAE: 0.3113\n",
            "Epoch 26/10000\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.1042 - MAE: 0.0888 - val_loss: 0.3399 - val_MAE: 0.3107\n",
            "Epoch 27/10000\n",
            "50/50 [==============================] - 6s 113ms/step - loss: 0.1033 - MAE: 0.0883 - val_loss: 0.3374 - val_MAE: 0.3058\n",
            "Epoch 28/10000\n",
            "50/50 [==============================] - 5s 90ms/step - loss: 0.1025 - MAE: 0.0877 - val_loss: 0.3364 - val_MAE: 0.3084\n",
            "Epoch 29/10000\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.1017 - MAE: 0.0872 - val_loss: 0.3342 - val_MAE: 0.3050\n",
            "Epoch 30/10000\n",
            "50/50 [==============================] - 6s 115ms/step - loss: 0.1010 - MAE: 0.0867 - val_loss: 0.3334 - val_MAE: 0.3057\n",
            "Epoch 31/10000\n",
            "50/50 [==============================] - 5s 90ms/step - loss: 0.1003 - MAE: 0.0863 - val_loss: 0.3321 - val_MAE: 0.3056\n",
            "Epoch 32/10000\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.0997 - MAE: 0.0859 - val_loss: 0.3302 - val_MAE: 0.3023\n",
            "Epoch 33/10000\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0990 - MAE: 0.0854 - val_loss: 0.3286 - val_MAE: 0.3013\n",
            "Epoch 34/10000\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.0985 - MAE: 0.0851 - val_loss: 0.3269 - val_MAE: 0.2991\n",
            "Epoch 35/10000\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.0979 - MAE: 0.0847 - val_loss: 0.3250 - val_MAE: 0.2974\n",
            "Epoch 36/10000\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.0973 - MAE: 0.0843 - val_loss: 0.3242 - val_MAE: 0.2984\n",
            "Epoch 37/10000\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.0968 - MAE: 0.0840 - val_loss: 0.3230 - val_MAE: 0.2959\n",
            "Epoch 38/10000\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.0962 - MAE: 0.0836 - val_loss: 0.3215 - val_MAE: 0.2950\n",
            "Epoch 39/10000\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.0958 - MAE: 0.0834 - val_loss: 0.3195 - val_MAE: 0.2922\n",
            "Epoch 40/10000\n",
            "50/50 [==============================] - 5s 103ms/step - loss: 0.0953 - MAE: 0.0831 - val_loss: 0.3188 - val_MAE: 0.2915\n",
            "Epoch 41/10000\n",
            "50/50 [==============================] - 5s 105ms/step - loss: 0.0949 - MAE: 0.0828 - val_loss: 0.3187 - val_MAE: 0.2933\n",
            "Epoch 42/10000\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.0944 - MAE: 0.0825 - val_loss: 0.3177 - val_MAE: 0.2941\n",
            "Epoch 43/10000\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.0940 - MAE: 0.0823 - val_loss: 0.3166 - val_MAE: 0.2913\n",
            "Epoch 44/10000\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.0935 - MAE: 0.0820 - val_loss: 0.3141 - val_MAE: 0.2862\n",
            "Epoch 45/10000\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0932 - MAE: 0.0817 - val_loss: 0.3130 - val_MAE: 0.2868\n",
            "Epoch 46/10000\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.0927 - MAE: 0.0814 - val_loss: 0.3130 - val_MAE: 0.2884\n",
            "Epoch 47/10000\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0924 - MAE: 0.0812 - val_loss: 0.3122 - val_MAE: 0.2886\n",
            "Epoch 48/10000\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.0920 - MAE: 0.0810 - val_loss: 0.3107 - val_MAE: 0.2867\n",
            "Epoch 49/10000\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.0917 - MAE: 0.0808 - val_loss: 0.3108 - val_MAE: 0.2878\n",
            "Epoch 50/10000\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.0913 - MAE: 0.0805 - val_loss: 0.3094 - val_MAE: 0.2873\n",
            "Epoch 51/10000\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.0910 - MAE: 0.0804 - val_loss: 0.3076 - val_MAE: 0.2832\n",
            "Epoch 52/10000\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.0906 - MAE: 0.0801 - val_loss: 0.3071 - val_MAE: 0.2837\n",
            "Epoch 53/10000\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0903 - MAE: 0.0800 - val_loss: 0.3058 - val_MAE: 0.2822\n",
            "Epoch 54/10000\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.0900 - MAE: 0.0797 - val_loss: 0.3052 - val_MAE: 0.2818\n",
            "Epoch 55/10000\n",
            "50/50 [==============================] - 5s 90ms/step - loss: 0.0898 - MAE: 0.0797 - val_loss: 0.3041 - val_MAE: 0.2799\n",
            "Epoch 56/10000\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.0894 - MAE: 0.0794 - val_loss: 0.3036 - val_MAE: 0.2803\n",
            "Epoch 57/10000\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.0891 - MAE: 0.0793 - val_loss: 0.3026 - val_MAE: 0.2799\n",
            "Epoch 58/10000\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.0888 - MAE: 0.0791 - val_loss: 0.3027 - val_MAE: 0.2807\n",
            "Epoch 59/10000\n",
            "46/50 [==========================>...] - ETA: 0s - loss: 0.0886 - MAE: 0.0790"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-6efc7cfee727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# beta regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#print(rnn_input[:6])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_calc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnn_input_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \"\"\"\n\u001b[1;32m   1158\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# we do have 6 elements, each one with: p_recall, delta, history_seen, history_correct, session_seen, session_correct\n",
        "# we keep 5 of those for the LSTM RNN\n",
        "# we use another network with the 6th element and 5 features (all except p_recall)\n",
        "# we connect the networks and try to predict the last p_recall\n",
        "\n",
        "tf.keras.backend.clear_session() \n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "class HalfLifeLayer(tf.keras.layers.Layer):\n",
        "    \n",
        "  def __init__(self):\n",
        "    super(HalfLifeLayer, self).__init__()\n",
        "\n",
        "  def build(self, input_shape): \n",
        "    return\n",
        "\n",
        "  def call(self, inputs):\n",
        "      # outputs shape \n",
        "      # curve:\n",
        "      # p = 2^(−∆/h)\n",
        "      #tf.keras.backend.print_tensor(inputs, message='y = ')\n",
        "      time = inputs[:,0:1]\n",
        " \n",
        "      pol = inputs[:,2:3]\n",
        "      for i in range(5):\n",
        "          pol = pol + tf.pow(time, i+1)*inputs[:,(2+i+1):(2+i+2)] \n",
        "      # pol = tf.pow(time, 2)*inputs[:,2:3]+tf.pow(time, 1)*inputs[:,3:4]+inputs[:,4:5]\n",
        "      return tf.pow(2.0, -tf.divide(time, inputs[:,1:2]+1e-6)) \n",
        "\n",
        "rnn_layer_input = Input(shape=rnn_input[0].shape)\n",
        "rnn_layer_0 = Masking(mask_value=-1.0)(rnn_layer_input)\n",
        "rnn_layer_1 = GRU(20,dropout=0.1, recurrent_dropout=0.13, kernel_regularizer=regularizers.L2(0.001), recurrent_regularizer=regularizers.L2(0.001))(rnn_layer_0)\n",
        "dense_layer_0 = Dense(40, activation='relu',  kernel_regularizer=regularizers.L2(0.001), activity_regularizer=regularizers.L2(0.01)) (rnn_layer_1)\n",
        "dense_layer_1 = Dense(7, activation='relu', name=\"cases\") (dense_layer_0) \n",
        "\n",
        "delta_layer_input = Input(shape=delta_input[0].shape)\n",
        "merge = concatenate([delta_layer_input, dense_layer_1]) # in order: delta, half life\n",
        "output_layer = HalfLifeLayer()(merge)\n",
        "\n",
        "#dense_layer_000 = Dropout(0.13)(Dense(20, activation='relu',  kernel_regularizer=regularizers.L2(0.001), activity_regularizer=regularizers.L2(0.01)) (rnn_layer_1))\n",
        "#output_layer = Dense(1, activation='sigmoid', name=\"cases\") (dense_layer_000)  \n",
        "\n",
        "model = Model([rnn_layer_input, delta_layer_input], [output_layer])\n",
        "metrics=[\"MAE\"]\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-2), loss=\"mae\", metrics=metrics)\n",
        "\n",
        "\n",
        "# beta regression \n",
        "#print(rnn_input[:6])\n",
        "model.fit([rnn_input, delta_input], output,sample_weight=weights_calc, epochs=10000, batch_size=10000, validation_data=([rnn_input_test, delta_input_test], output_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xZkHW2VmoFa",
        "outputId": "c54e6e44-1bd8-4c32-d3f5-4cfbad75e8d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
            " [ 9.84615385e-01  1.89668519e+01  1.00000000e+00]\n",
            " [ 1.00000000e+00  3.18634259e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  5.49768519e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.36805556e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  1.52546296e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  2.61458333e-02  2.00000000e+00]\n",
            " [ 1.00000000e+00  1.96925926e+00  1.00000000e+00]\n",
            " [ 1.00000000e+00  2.41087963e-02  1.00000000e+00]\n",
            " [ 1.00000000e+00  4.59490741e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  3.91203704e-03  1.00000000e+00]\n",
            " [ 1.00000000e+00  4.12615741e-02  3.00000000e+00]\n",
            " [ 6.66666667e-01  7.27511574e-01  1.00000000e+00]]\n",
            "[0.66666667]\n"
          ]
        }
      ],
      "source": [
        "print(rnn_input[7])\n",
        "print(output[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9m5GhqyLnU4"
      },
      "outputs": [],
      "source": [
        "model.evaluate([rnn_input_test[:,0,:], rnn_input_test[:,1,:],rnn_input_test[:,2,:],rnn_input_test[:,3,:],rnn_input_test[:,4,:],rnn_input_test[:,5,:], dense_input_test], output_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPMAhWaHrzQJ",
        "outputId": "ee189c1c-c67b-4457-a944-64a16b3a50dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.249386574074074"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn_input_test[3][-1][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOYzXFPatU-k",
        "outputId": "37de3c3c-c11f-435f-ef73-72c4ec87c587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.016168981481481\n"
          ]
        }
      ],
      "source": [
        "maxx = 0\n",
        "for i in rnn_input:\n",
        "    if i[-1][1] > maxx:\n",
        "        maxx = i[-1][1]\n",
        "print(maxx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6itlhJGJ7ZS",
        "outputId": "3de5ed7f-da66-497c-c3fc-4ef97a96c350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [-1. -1.]\n",
            "  [ 0.  0.]\n",
            "  [ 0.  1.]\n",
            "  [ 0.  1.]\n",
            "  [ 1.  1.]\n",
            "  [ 1.  3.]\n",
            "  [ 1.  5.]\n",
            "  [ 1.  7.]\n",
            "  [ 1. 10.]\n",
            "  [ 1. 20.]\n",
            "  [ 0. 60.]]]\n",
            "[[1.]]\n",
            "1789\n"
          ]
        }
      ],
      "source": [
        "\n",
        "  ind = np.random.randint(0, len(rnn_input_test))\n",
        "  example_rnn = np.array(np.expand_dims(rnn_input_test[ind], 0))\n",
        "  example_dense = np.array(np.expand_dims(delta_input_test[ind], 0))\n",
        "  print(example_rnn) \n",
        "  print(example_dense) \n",
        "  print(ind)\n",
        " \n",
        "  if True:\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(100):\n",
        "      j = (i)\n",
        "      x.append(j)\n",
        "      \n",
        "      '''\n",
        "      for i in range(len(example_rnn[0])):\n",
        "          example_rnn[0][i][0] = 1\n",
        "          example_rnn[0][i][1] = 100\n",
        "      '''\n",
        "      example_dense[0][0] = j \n",
        "      \n",
        "      #print(example_dense)\n",
        "      #print(model.predict([example_rnn],verbose = 0))\n",
        "      y.append(model.predict([example_rnn, example_dense],verbose = 0)[0][0])\n",
        "!pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# make data\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "# plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(x, y, linewidth=2.0)\n",
        " \n",
        "\n",
        "plt.show()\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycfarcNDtU-m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}